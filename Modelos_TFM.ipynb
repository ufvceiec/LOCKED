{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-21 11:50:52.324425\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "hora_inicio_codigo = datetime.datetime.now()\n",
    "print(hora_inicio_codigo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2536,
     "status": "ok",
     "timestamp": 1726144347515,
     "user": {
      "displayName": "BERTA PADILLA BAEZA",
      "userId": "17038178126289984285"
     },
     "user_tz": -120
    },
    "id": "f8WHPvknAQFr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "import chardet\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV, StratifiedKFold, train_test_split, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "editable": true,
    "executionInfo": {
     "elapsed": 5557,
     "status": "ok",
     "timestamp": 1726144398672,
     "user": {
      "displayName": "BERTA PADILLA BAEZA",
      "userId": "17038178126289984285"
     },
     "user_tz": -120
    },
    "id": "Ywp9i282B5y8",
    "outputId": "8a9f41c1-134b-46f2-f836-463328424002",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codificación detectada: utf-8\n",
      "Codificación detectada: utf-8\n"
     ]
    }
   ],
   "source": [
    "data_file = './CSV_ALFREDO/final_data_numeric.csv'\n",
    "\n",
    "with open(data_file, 'rb') as file:\n",
    "    resultado = chardet.detect(file.read(10000))\n",
    "\n",
    "# Ver la codificación detectada\n",
    "print(f\"Codificación detectada: {resultado['encoding']}\")\n",
    "\n",
    "# Leer el archivo CSV con la codificación detectada\n",
    "data = pd.read_csv(data_file, sep=';', encoding=resultado['encoding'])\n",
    "\n",
    "y_file = './CSV_ALFREDO/result.csv'\n",
    "\n",
    "# Ver la codificación detectada\n",
    "print(f\"Codificación detectada: {resultado['encoding']}\")\n",
    "\n",
    "# Leer el archivo CSV con la codificación detectada\n",
    "y = pd.read_csv(y_file, sep=';', encoding=resultado['encoding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoXGFgO-DvBG"
   },
   "source": [
    "# Separamos en X_Train, X_Test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definición de las columnas para cada subset (ajustado según los nombres exactos)\n",
    "demographic_columns = [\n",
    "    'por_favor_indique_el_genero_con_el_que_se_identifica:',  # Gender\n",
    "    'indique_su_estado_civil:',  # Marital Status\n",
    "    '¿tiene_la_nacionalidad_europea?',  # Nationality\n",
    "    '¿cual_es_el_estado_actual_de_su_documentacion?',  # Current Documentation Status\n",
    "    '¿cual_es_el_maximo_nivel_educativo_que_ha_terminado?',  # Education Level\n",
    "    'por_favor,_indique_su_estructura_de_convivencia_habitual_durante_los_12_meses_anteriores_al_confinamiento:',  # Family Structure before COVID\n",
    "    'por_favor,_indique_su_estructura_de_convivencia_habitual_durante_la_reclusion:',  # Family Structure during COVID\n",
    "    'por_favor_indique_el_numero_de_menores_a_su_cargo_durante_la_cuarentena:',  # Number of Minors in Care During COVID\n",
    "    'por_favor_indique_el_numero_de_personas_dependientes_mayores_de_18_años_a_su_cargo_(incluyendo_personas_mayores,_personas_con_diversidad_funcional)_durante_la_cuarentena:',  # Number of Dependents\n",
    "    'por_favor,_indique_con_cuanta_gente_tenia_contacto_habitualmente_en_un_dia_normal_antes__de_la_cuarentena_(incluyendo_el_hogar,_lo_laboral,_lo_social...)._nos_referimos_a_contactos_individuales_cara_a_cara,_es_decir,_con_las_que_charla_o_trata_diferentes_asuntos_en_persona.',  # Social Contacts Before COVID\n",
    "    'por_favor,_indique_con_cuanta_gente_tiene/tuvo_contacto_habitualmente_en_un_dia_normal_durante_la_cuarentena__(incluyendo_el_hogar,_lo_laboral,_lo_social...)._nos_referimos_a_contactos_individuales_cara_a_cara,_es_decir,_con_las_que_charla_o_trata_diferentes_asuntos_en_persona.'  # Social Contacts During COVID\n",
    "    ]\n",
    "\n",
    "living_columns = [\n",
    "    'por_favor,_indique_el_espacio_en_el_que_vive/vivia_durante_el_confinamiento:',  # Type of Living Space During Confinement\n",
    "    'por_favor_indique_si_es_dueño_de_su_vivienda_o_vive_alquilado/a:',  # Property Ownership\n",
    "    '¿cuantos_metros_cuadrados_utiles_(los_que_puede_pisar)_tiene/tenia_su_espacio_de_residencia_durante_la_cuarentena?',  # Square Meters of Living Space\n",
    "    'diria_que_su_espacio_de_residencia_durante_la_cuarentena_tiene:',  # Light During Quarantine\n",
    "    'diria_que_su_espacio_de_residencia_durante_la_cuarentena_tiene:.1',  # Ventilation During Quarantine\n",
    "    'teniendo_en_mente_su_lugar_de_residencia_durante_el_confinamiento,_por_favor,_indique._numero_de_habitaciones_sin_contar_baño_y_cocina:',  # Number of Rooms\n",
    "    'teniendo_en_mente_su_lugar_de_residencia_durante_el_confinamiento,_por_favor,_indique._numero_de_personas_con_las_que_cohabitaba/cohabita:',  # Number of Cohabitants\n",
    "    'teniendo_en_mente_su_lugar_de_residencia_durante_el_confinamiento,_por_favor,_indique._numero_de_personas_en_su_mismo_dormitorio_excluyendose_a_usted_mismo/a:',  # Number of Cohabitants in the Same Room\n",
    "    '¿cuantas_veces_a_la_semana_ha_salido_de_casa_durante_la_cuarentena?',  # Outings During Quarantine\n",
    "    'la_idea_de_que_deberia_ser_castigado/a_por_sus_pecados',  # Assessment of Self Punishment\n",
    "]\n",
    "\n",
    "economic_columns = [\n",
    "    'situacion_laboral_antes_(en_los_12_meses_anteriores_al_inicio_de_la_cuarentena_o_la_mayor_parte_de_ese_tiempo)',  # Employment Status Before Quarantine\n",
    "    '¿que_duracion_tenia_su_jornada_laboral_antes_(en_los_12_meses_anteriores_al_inicio_de_la_cuarentena_o_la_mayor_parte_de_ese_tiempo):',  # Working Hours Before Quarantine\n",
    "    '¿cual_ha_sido_su_situacion_laboral_durante_la_cuarentena?',  # Employment Status During Quarantine\n",
    "    '¿cual_considera_que_podria_ser_su_situacion_laboral_o_academica_despu√âs_de_la_crisis_provocada_por_el_coronavirus_(en_los_12_meses_posteriores_al_fin_de_la_cuarentena_o_la_mayor_parte_de_ese_tiempo):?',  # Employment Status After Quarantine\n",
    "    'en_los_ultimos_12_meses_antes_del_confinamiento,_¿cual_fue_la_principal_ocupacion_de_la_persona_que_aporta_un_mayor_importe_economico_al_hogar?',  # Occupation of the Person with the Highest Economic Contribution\n",
    "    '¿cual_era_el_nivel_aproximado_de_ingresos_mensuales_netos_regulares_en_su_hogar_(unidad_en_la_que_se_comparten_gastos:_individuo,_pareja,_familia...)_antes_de_la_cuarentena_(en_los_12_meses_anteriores_al_inicio_de_la_cuarentena_o_la_mayor_parte_de_ese_tiempo):',  # Net Monthly Income Before COVID\n",
    "    '¿cual_era_el_nivel_aproximado_de_ingresos_mensuales_netos_regulares_en_su_hogar_(unidad_en_la_que_se_comparten_gastos:_individuo,_pareja,_familia...)_durante_la_cuarentena:',  # Net Monthly Income During COVID\n",
    "    'durante_el_confinamiento_en_su_hogar:',  # Household Conditions During Confinement\n",
    "    'supongamos_que_usted_(y_su_conyuge_o_pareja)_convierte_en_dinero_todos_sus_fondos_en_cuentas_corrientes_y/o_de_ahorros,_inversiones_en_bolsa,_bonos/letras,_bienes_inmuebles,_y_venden_su_casa,_sus_vehiculos_y_todas_sus_cosas_de_valor._a_continuacion,_supongamos_que_el_dinero_de_todas_estas_operaciones_lo_utiliza_para_pagar_su_hipoteca_y_otros_creditos,_prestamos,_deudas_y_tarjetas_de_credito._¿le_quedaria_dinero_despues_de_pagar_todas_sus_deudas,_o_todavia_deberia_dinero?_(basta_con_un_estimacion_aproximada).',  # Financial Assessment After Liquidation\n",
    "]\n",
    "\n",
    "health_columns = [\n",
    "    'condicion_de_salud',  # Health Condition and Specific Needs\n",
    "    'recibe_tratamiento_o_medicacion_psiquiatrica_actualmente:',  # Psychiatric Treatment\n",
    "    'recibe_tratamiento_psicologico_o_sigue_una_terapia_actualmente:',  # Psychological Treatment\n",
    "    'por_favor_indique_si_necesita_ayuda_para_las_tareas_cotidianas_y_de_autocuidado_como_hacer_la_compra,_realizar_las_tareas_del_hogar,_lavarse_y_peinarse,_cocinar,_gestionar_el_dinero,_etc.',  # Help for Daily Tasks\n",
    "    'por_favor_indique,_si_lo_hay,_el_grado_de_discapacidad_que_indique_su_certificado_%_reconocido_(0_si_no_tiene):',  # Chronic Illness\n",
    "    'por_favor,_indique_si_en_el_pasado_usted_ha_tenido_algun_intento_de_suicidio:',\n",
    "    'por_favor_indique_si_le_han_diagnosticado_de_infeccion_por_coronavirus',\n",
    "    'en_el_caso_de_tener_o_haber_tenido_un_diagnostico_de_coronavirus,_¿como_valoraria_la_severidad_de_la_enfermedad?',\n",
    "    'en_este_caso,_¿permanecio_aislado/a_dentro_del_domicilio_(sin_salir_de_una_habitacion_y_sin_compañia_durante_la_duracion_de_los_sintomas_y_15_dias_mas)?',\n",
    "    'alguna_persona_de_su_familia_diagnosticada_de_infeccion_por_coronavirus,_¿ha_convivido_en_su_hogar_durante_el_proceso_de_su_enfermedad?',\n",
    "    'en_caso_afirmativo,_valore,_por_favor,_la_severidad_de_la_enfermedad_(tenga_en_cuenta_el_de_mayor_gravedad_en_caso_de_ser_varios_casos)',\n",
    "    'familiar_covid'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subconjuntos de datos guardados exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# Crear subconjuntos de datos\n",
    "demographic_df = data[demographic_columns]\n",
    "living_df = data[living_columns]\n",
    "economic_df = data[economic_columns]\n",
    "health_df = data[health_columns]\n",
    "\n",
    "# Guardar los subconjuntos en archivos CSV\n",
    "demographic_df.to_csv('./sets/demographic_data.csv', sep=';', index=False)\n",
    "#display(demographic_df)\n",
    "living_df.to_csv('./sets/living_data.csv', sep=';', index=False)\n",
    "#display(living_df)\n",
    "economic_df.to_csv('./sets/economic_data.csv', sep=';', index=False)\n",
    "#display(economic_df)\n",
    "health_df.to_csv('./sets/health_data.csv', sep=';', index=False)\n",
    "#display(health_df)\n",
    "\n",
    "datasets = [demographic_df, living_df, economic_df, health_df]\n",
    "\n",
    "print(\"Subconjuntos de datos guardados exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos en './sets': ['demographic_data.csv', 'economic_data.csv', 'health_data.csv', 'living_data.csv']\n"
     ]
    }
   ],
   "source": [
    "# Directorios\n",
    "input_dir = './sets'\n",
    "output_dir = './entrenamiento'\n",
    "\n",
    "# Asegurarse de que el directorio de salida existe\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Leer los archivos en el directorio './sets'\n",
    "sub_sets = os.listdir(input_dir)\n",
    "\n",
    "sub_sets = [x for x in sub_sets if x.endswith('.csv')]\n",
    "\n",
    "print(\"Archivos en './sets':\", sub_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codificación detectada para demographic_data.csv: EUC-JP\n",
      "Codificación detectada para economic_data.csv: utf-8\n",
      "Codificación detectada para health_data.csv: EUC-JP\n",
      "Codificación detectada para living_data.csv: EUC-JP\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "\n",
    "# Cargar todos los datasets en la lista datasets\n",
    "for sub_set in sub_sets:\n",
    "    data_file = f'{input_dir}/{sub_set}'\n",
    "    \n",
    "    with open(data_file, 'rb') as file:\n",
    "        resultado = chardet.detect(file.read(10000))\n",
    "\n",
    "    # Ver la codificación detectada\n",
    "    print(f\"Codificación detectada para {sub_set}: {resultado['encoding']}\")\n",
    "    \n",
    "    # Leer el archivo CSV con la codificación detectada\n",
    "    data = pd.read_csv(data_file, sep=';', encoding=resultado['encoding'])\n",
    "    datasets.append((sub_set, data))  # Guarda el nombre del archivo y el DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codificación detectada para 'result.csv': utf-8\n",
      "Nombres de las columnas en 'result.csv': ['Hostilidad', 'Somatización', 'Depresión', 'Obsesión-compulsión', 'Ansiedad', 'Sensibilidad interpersonal', 'Agorafobia', 'Ideación paranoide', 'Psicoticismo']\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo 'result.csv' para obtener las columnas de interés\n",
    "y_file = './CSV_ALFREDO/result.csv'\n",
    "\n",
    "with open(y_file, 'rb') as file:\n",
    "    resultado = chardet.detect(file.read(10000))\n",
    "\n",
    "# Ver la codificación detectada\n",
    "print(f\"Codificación detectada para 'result.csv': {resultado['encoding']}\")\n",
    "\n",
    "# Leer el archivo CSV con la codificación detectada\n",
    "y = pd.read_csv(y_file, sep=';', encoding=resultado['encoding'])\n",
    "\n",
    "# Almacenar los nombres de las columnas en un array\n",
    "columnas = y.columns.to_list()\n",
    "print(\"Nombres de las columnas en 'result.csv':\", columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado: ./entrenamiento/demographic_data_with_Hostilidad.csv\n",
      "Archivo guardado: ./entrenamiento/demographic_data_with_Somatización.csv\n",
      "Archivo guardado: ./entrenamiento/demographic_data_with_Depresión.csv\n",
      "Archivo guardado: ./entrenamiento/demographic_data_with_Obsesión-compulsión.csv\n",
      "Archivo guardado: ./entrenamiento/demographic_data_with_Ansiedad.csv\n",
      "Archivo guardado: ./entrenamiento/demographic_data_with_Sensibilidad interpersonal.csv\n",
      "Archivo guardado: ./entrenamiento/demographic_data_with_Agorafobia.csv\n",
      "Archivo guardado: ./entrenamiento/demographic_data_with_Ideación paranoide.csv\n",
      "Archivo guardado: ./entrenamiento/demographic_data_with_Psicoticismo.csv\n",
      "Archivo guardado: ./entrenamiento/economic_data_with_Hostilidad.csv\n",
      "Archivo guardado: ./entrenamiento/economic_data_with_Somatización.csv\n",
      "Archivo guardado: ./entrenamiento/economic_data_with_Depresión.csv\n",
      "Archivo guardado: ./entrenamiento/economic_data_with_Obsesión-compulsión.csv\n",
      "Archivo guardado: ./entrenamiento/economic_data_with_Ansiedad.csv\n",
      "Archivo guardado: ./entrenamiento/economic_data_with_Sensibilidad interpersonal.csv\n",
      "Archivo guardado: ./entrenamiento/economic_data_with_Agorafobia.csv\n",
      "Archivo guardado: ./entrenamiento/economic_data_with_Ideación paranoide.csv\n",
      "Archivo guardado: ./entrenamiento/economic_data_with_Psicoticismo.csv\n",
      "Archivo guardado: ./entrenamiento/health_data_with_Hostilidad.csv\n",
      "Archivo guardado: ./entrenamiento/health_data_with_Somatización.csv\n",
      "Archivo guardado: ./entrenamiento/health_data_with_Depresión.csv\n",
      "Archivo guardado: ./entrenamiento/health_data_with_Obsesión-compulsión.csv\n",
      "Archivo guardado: ./entrenamiento/health_data_with_Ansiedad.csv\n",
      "Archivo guardado: ./entrenamiento/health_data_with_Sensibilidad interpersonal.csv\n",
      "Archivo guardado: ./entrenamiento/health_data_with_Agorafobia.csv\n",
      "Archivo guardado: ./entrenamiento/health_data_with_Ideación paranoide.csv\n",
      "Archivo guardado: ./entrenamiento/health_data_with_Psicoticismo.csv\n",
      "Archivo guardado: ./entrenamiento/living_data_with_Hostilidad.csv\n",
      "Archivo guardado: ./entrenamiento/living_data_with_Somatización.csv\n",
      "Archivo guardado: ./entrenamiento/living_data_with_Depresión.csv\n",
      "Archivo guardado: ./entrenamiento/living_data_with_Obsesión-compulsión.csv\n",
      "Archivo guardado: ./entrenamiento/living_data_with_Ansiedad.csv\n",
      "Archivo guardado: ./entrenamiento/living_data_with_Sensibilidad interpersonal.csv\n",
      "Archivo guardado: ./entrenamiento/living_data_with_Agorafobia.csv\n",
      "Archivo guardado: ./entrenamiento/living_data_with_Ideación paranoide.csv\n",
      "Archivo guardado: ./entrenamiento/living_data_with_Psicoticismo.csv\n"
     ]
    }
   ],
   "source": [
    "# Crear nuevos datasets combinando cada sub_set con cada columna de y\n",
    "for sub_set_name, dataset in datasets:\n",
    "    for columna in columnas:\n",
    "        # Crear un nuevo DataFrame con la columna de y y los datos del dataset original\n",
    "        new_dataset = dataset.copy()  # Hacer una copia del dataset original\n",
    "        new_dataset[columna] = y[columna]  # Añadir la columna de 'y' al nuevo dataset\n",
    "        \n",
    "        # Guardar el nuevo DataFrame en un nuevo archivo CSV\n",
    "        output_file = f'{output_dir}/{sub_set_name[:-4]}_with_{columna}.csv'\n",
    "        new_dataset.to_csv(output_file, sep=';', index=False, encoding='utf-8')\n",
    "        \n",
    "        print(f\"Archivo guardado: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets encontrados: ['demographic_data_with_Agorafobia.csv', 'demographic_data_with_Ansiedad.csv', 'demographic_data_with_Depresión.csv', 'demographic_data_with_Hostilidad.csv', 'demographic_data_with_Ideación paranoide.csv', 'demographic_data_with_Obsesión-compulsión.csv', 'demographic_data_with_Psicoticismo.csv', 'demographic_data_with_Sensibilidad interpersonal.csv', 'demographic_data_with_Somatización.csv', 'economic_data_with_Agorafobia.csv', 'economic_data_with_Ansiedad.csv', 'economic_data_with_Depresión.csv', 'economic_data_with_Hostilidad.csv', 'economic_data_with_Ideación paranoide.csv', 'economic_data_with_Obsesión-compulsión.csv', 'economic_data_with_Psicoticismo.csv', 'economic_data_with_Sensibilidad interpersonal.csv', 'economic_data_with_Somatización.csv', 'health_data_with_Agorafobia.csv', 'health_data_with_Ansiedad.csv', 'health_data_with_Depresión.csv', 'health_data_with_Hostilidad.csv', 'health_data_with_Ideación paranoide.csv', 'health_data_with_Obsesión-compulsión.csv', 'health_data_with_Psicoticismo.csv', 'health_data_with_Sensibilidad interpersonal.csv', 'health_data_with_Somatización.csv', 'living_data_with_Agorafobia.csv', 'living_data_with_Ansiedad.csv', 'living_data_with_Depresión.csv', 'living_data_with_Hostilidad.csv', 'living_data_with_Ideación paranoide.csv', 'living_data_with_Obsesión-compulsión.csv', 'living_data_with_Psicoticismo.csv', 'living_data_with_Sensibilidad interpersonal.csv', 'living_data_with_Somatización.csv']\n"
     ]
    }
   ],
   "source": [
    "# Directorio donde están los datasets\n",
    "data_dir = './entrenamiento'\n",
    "datasets = os.listdir(data_dir)\n",
    "balanced_dir = './entrenamiento_balanceado'\n",
    "\n",
    "# Crear el directorio si no existe\n",
    "os.makedirs(balanced_dir, exist_ok=True)\n",
    "\n",
    "# Filtrar archivos que no son CSV\n",
    "datasets = [d for d in datasets if d.endswith('.csv')]\n",
    "\n",
    "print(f'Datasets encontrados: {datasets}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n",
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_demographic_data_with_Agorafobia.csv\n",
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_demographic_data_with_Ansiedad.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n",
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_demographic_data_with_Depresión.csv\n",
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_demographic_data_with_Hostilidad.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n",
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_demographic_data_with_Ideación paranoide.csv\n",
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_demographic_data_with_Obsesión-compulsión.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n",
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_demographic_data_with_Psicoticismo.csv\n",
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_demographic_data_with_Sensibilidad interpersonal.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_demographic_data_with_Somatización.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_economic_data_with_Agorafobia.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n",
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_economic_data_with_Ansiedad.csv\n",
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_economic_data_with_Depresión.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n",
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_economic_data_with_Hostilidad.csv\n",
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_economic_data_with_Ideación paranoide.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_economic_data_with_Obsesión-compulsión.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_economic_data_with_Psicoticismo.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n",
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_economic_data_with_Sensibilidad interpersonal.csv\n",
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_economic_data_with_Somatización.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_health_data_with_Agorafobia.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_health_data_with_Ansiedad.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_health_data_with_Depresión.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_health_data_with_Hostilidad.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_health_data_with_Ideación paranoide.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_health_data_with_Obsesión-compulsión.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_health_data_with_Psicoticismo.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_health_data_with_Sensibilidad interpersonal.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n",
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_health_data_with_Somatización.csv\n",
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_living_data_with_Agorafobia.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n",
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_living_data_with_Ansiedad.csv\n",
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_living_data_with_Depresión.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_living_data_with_Hostilidad.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n",
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_living_data_with_Ideación paranoide.csv\n",
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_living_data_with_Obsesión-compulsión.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n",
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_living_data_with_Psicoticismo.csv\n",
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_living_data_with_Sensibilidad interpersonal.csv\n",
      "SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: ./entrenamiento_balanceado\\balanceado_living_data_with_Somatización.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceiec09\\AppData\\Local\\Temp\\ipykernel_15132\\1170576296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n"
     ]
    }
   ],
   "source": [
    "for data_file in datasets:\n",
    "    # Cargar el dataset\n",
    "    data_path = os.path.join(data_dir, data_file)\n",
    "    data = pd.read_csv(data_path, sep=';')\n",
    "    \n",
    "    # Separar características y etiquetas\n",
    "    X = data.iloc[:, :-1]  # Todas las columnas menos la última\n",
    "    y = data.iloc[:, -1]   # Última columna\n",
    "\n",
    "    # Aplicar SMOTE para aumentar la clase minoritaria\n",
    "    smote = SMOTE(sampling_strategy='not minority', random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    \n",
    "    # Determinar el tamaño objetivo de la clase mayoritaria (igual al tamaño de la clase minoritaria original)\n",
    "    clase_min = y.value_counts().min()\n",
    "    \n",
    "    # Crear un DataFrame de las muestras resampleadas para manipulación\n",
    "    resampled_data = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "    resampled_data[str(data_file).split('_')[-1][:-4]] = y_resampled  # Suponiendo que str(data_file).split('_')[-1][:-4] es el nombre de la columna de etiquetas\n",
    "    \n",
    "    # Filtrar la clase mayoritaria y ordenar por la distancia a la media (u otra métrica)\n",
    "    clase_mayoritaria = resampled_data[resampled_data[str(data_file).split('_')[-1][:-4]] == y.mode()[0]]\n",
    "    clase_mayoritaria_mean = clase_mayoritaria.mean(axis=0)  # Calculamos la media de la clase mayoritaria\n",
    "    \n",
    "    # Ordenar la clase mayoritaria por proximidad a la media y seleccionar las primeras `clase_min` muestras\n",
    "    clase_mayoritaria['distancia'] = clase_mayoritaria.drop(columns=str(data_file).split('_')[-1][:-4]).apply(\n",
    "        lambda row: ((row - clase_mayoritaria_mean[:-1]) ** 2).sum(), axis=1)\n",
    "    clase_mayoritaria_sorted = clase_mayoritaria.sort_values(by='distancia').head(clase_min)\n",
    "    \n",
    "    # Filtrar la clase minoritaria\n",
    "    clase_minoritaria = resampled_data[resampled_data[str(data_file).split('_')[-1][:-4]] != y.mode()[0]]\n",
    "    \n",
    "    # Combinar clase mayoritaria balanceada y clase minoritaria\n",
    "    balanced_data = pd.concat([clase_mayoritaria_sorted, clase_minoritaria]).drop(columns='distancia')\n",
    "    \n",
    "    # Guardar el dataset balanceado\n",
    "    balanced_data_path = os.path.join(balanced_dir, f'balanceado_{data_file}')\n",
    "    balanced_data.to_csv(balanced_data_path, sep=';', index=False)\n",
    "    \n",
    "    print(f'SMOTE y downsampling no aleatorio aplicados. Dataset guardado como: {balanced_data_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8qx9Ye0H7Dg"
   },
   "source": [
    "# 1. Modelos de clasificación Binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfUT8_xWYnwa"
   },
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5096,
     "status": "ok",
     "timestamp": 1722678009346,
     "user": {
      "displayName": "BERTA PADILLA BAEZA",
      "userId": "17038178126289984285"
     },
     "user_tz": -120
    },
    "id": "bw1ZAnHnXlBP",
    "outputId": "f270a716-67f8-4c75-a1be-a87ab0987900"
   },
   "outputs": [],
   "source": [
    "# Diccionarios de hiperparámetros para cada modelo\n",
    "param_grids = {\n",
    "    'DecisionTree': {\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'degree': [3, 4, 5],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    },\n",
    "    'NaiveBayes': {\n",
    "        'var_smoothing': np.logspace(0, -9, num=10),\n",
    "    },\n",
    "    'LogisticRegression': [\n",
    "        {\n",
    "            'C': [0.01, 0.1, 1, 10, 100],\n",
    "            'penalty': ['l2'],\n",
    "            'solver': ['lbfgs'],\n",
    "            'max_iter': [100, 200, 500]\n",
    "        },\n",
    "        {\n",
    "            'C': [0.01, 0.1, 1, 10, 100],\n",
    "            'penalty': ['l1'],\n",
    "            'solver': ['liblinear'],\n",
    "            'max_iter': [100, 200, 500]\n",
    "        },\n",
    "        {\n",
    "            'C': [0.01, 0.1, 1, 10, 100],\n",
    "            'penalty': ['l2'],\n",
    "            'solver': ['liblinear'],\n",
    "            'max_iter': [100, 200, 500]\n",
    "        }\n",
    "    ],\n",
    "    'MLP': {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam', 'sgd'],\n",
    "        'alpha': [0.0001, 0.001],\n",
    "        'learning_rate': ['constant', 'adaptive']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificadores\n",
    "classifiers = {\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42),  # Se necesita probability=True para SHAP\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'NaiveBayes': GaussianNB(),\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'MLP': MLPClassifier(random_state=42, max_iter=1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular sensibilidad y especificidad\n",
    "def calcular_sensibilidad_especificidad_conjunto(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensibilidad = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    especificidad = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    return sensibilidad, especificidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular los valores SHAP\n",
    "def calcular_shap_values(clasificador, X_train, X_test, nombre_algoritmo):\n",
    "    explainer = None\n",
    "\n",
    "    # Reducir el fondo para la explicación\n",
    "    background = shap.sample(X_train, 33)  # Reducir si el conjunto es grande\n",
    "\n",
    "    # Seleccionar el tipo de explicador según el modelo\n",
    "    if nombre_algoritmo in ['SVM', 'NaiveBayes', 'LogisticRegression', 'MLP']:\n",
    "        explainer = shap.KernelExplainer(clasificador.predict_proba, background)\n",
    "    elif nombre_algoritmo in ['RandomForest', 'DecisionTree', 'GradientBoosting']:\n",
    "        explainer = shap.TreeExplainer(clasificador)\n",
    "\n",
    "    # Calcular valores SHAP\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    # Verificar si shap_values es una lista (caso de clasificación binaria)\n",
    "    if isinstance(shap_values, list):\n",
    "        # Seleccionar los valores SHAP de la clase positiva (índice 1)\n",
    "        shap_values = shap_values[1]\n",
    "    \n",
    "    # Verificar dimensiones del resultado y ajustar\n",
    "    if shap_values.ndim == 3:  # Caso raro con dimensiones adicionales\n",
    "        shap_values = shap_values[:, :, 1]  # Seleccionar la clase positiva\n",
    "\n",
    "    # Crear el DataFrame SHAP\n",
    "    shap_df = pd.DataFrame(shap_values, columns=X_test.columns)\n",
    "\n",
    "    return shap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio de datos\n",
    "data_dir = './entrenamiento_balanceado'\n",
    "\n",
    "datasets = os.listdir(data_dir)\n",
    "\n",
    "datasets = [x for x in datasets if x.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de particiones (folds) en la validación cruzada\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "resultados_totales = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3017944849.py, line 87)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[18], line 87\u001b[1;36m\u001b[0m\n\u001b[1;33m    tiempos_clasificadores[f'{nombre_algoritmo}_{clasificador}']['Tiempo fin'] =\u001b[0m\n\u001b[1;37m                                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tiempos_clasificadores = {}\n",
    "\n",
    "for dataset in tqdm(datasets, desc='Analizando', dynamic_ncols=True):\n",
    "    # Cargar datos de entrenamiento\n",
    "    datos_entrenamiento = pd.read_csv(f'./entrenamiento_balanceado/{dataset}', sep=';')\n",
    "    \n",
    "    # Extraer información de nombre del archivo\n",
    "    subset = dataset.split('_')[1]\n",
    "    issue = dataset.split('_')[-1].split('.')[0]\n",
    "    column = str(dataset)[:-4].split('_')[-1]\n",
    "    \n",
    "    # Separar en características y etiquetas\n",
    "    datos_entrenamiento_balanced = datos_entrenamiento.drop(columns=[column])\n",
    "    labels_columna_balanced = datos_entrenamiento[column]\n",
    "\n",
    "    # Dividir en conjunto de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        datos_entrenamiento_balanced, labels_columna_balanced, test_size=0.2, random_state=42, stratify=labels_columna_balanced\n",
    "    )\n",
    "    \n",
    "    # Evaluar cada clasificador\n",
    "    for nombre_algoritmo, clasificador in classifiers.items():\n",
    "\n",
    "        tiempo_inicio = datetime.datetime.now()\n",
    "        \n",
    "        # GridSearchCV para modelos con hiperparámetros\n",
    "        if param_grids[nombre_algoritmo]:  \n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=clasificador,\n",
    "                param_grid=param_grids[nombre_algoritmo],\n",
    "                scoring='accuracy',\n",
    "                cv=5,\n",
    "                n_jobs=-1,\n",
    "                return_train_score=True,\n",
    "                error_score='raise'\n",
    "            )\n",
    "\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            mejor_modelo = grid_search.best_estimator_\n",
    "            mejores_params = grid_search.best_params_\n",
    "\n",
    "            mean_train_accuracy = np.mean(grid_search.cv_results_['mean_train_score'])\n",
    "            std_train_accuracy = np.std(grid_search.cv_results_['mean_train_score'])\n",
    "            mean_val_accuracy = np.mean(grid_search.cv_results_['mean_test_score'])\n",
    "            std_val_accuracy = np.std(grid_search.cv_results_['mean_test_score'])\n",
    "            \n",
    "        else:  \n",
    "            mejor_modelo = clasificador.fit(X_train, y_train)\n",
    "            mejores_params = \"N/A\"\n",
    "            mean_train_accuracy = accuracy_score(y_train, mejor_modelo.predict(X_train))\n",
    "            std_train_accuracy = 0\n",
    "            mean_val_accuracy = accuracy_score(y_test, mejor_modelo.predict(X_test))\n",
    "            std_val_accuracy = 0\n",
    "        \n",
    "        # Evaluación final en conjunto de prueba\n",
    "        predicciones_test = mejor_modelo.predict(X_test)\n",
    "        accuracy_test = accuracy_score(y_test, predicciones_test)\n",
    "        sensibilidad_test, especificidad_test = calcular_sensibilidad_especificidad_conjunto(y_test, predicciones_test)\n",
    "\n",
    "        # Cálculo de los valores SHAP\n",
    "        shap_df = calcular_shap_values(mejor_modelo, X_train, X_test, nombre_algoritmo)\n",
    "\n",
    "        # Agregar cada fila al conjunto de resultados\n",
    "        for idx, row in shap_df.iterrows():\n",
    "            resultados_totales.append({\n",
    "                'dataset': dataset,\n",
    "                'subset': subset,\n",
    "                'issue': issue,\n",
    "                'algorithm': nombre_algoritmo,\n",
    "                'best_params': mejores_params,\n",
    "                'mean_train_accuracy': mean_train_accuracy,\n",
    "                'std_train_accuracy': std_train_accuracy,\n",
    "                'mean_val_accuracy': mean_val_accuracy,\n",
    "                'std_val_accuracy': std_val_accuracy,\n",
    "                'accuracy_test': accuracy_test,\n",
    "                'sensitivity_test': sensibilidad_test,\n",
    "                'specificity_test': especificidad_test,\n",
    "                'shap_feature_values': row.to_dict()\n",
    "            })\n",
    "        tiempo_fin = datetime.datetime.now()\n",
    "        diferencia = tiempo_fin - tiempo_inicio\n",
    "        tiempos_clasificadores[f'{nombre_algoritmo}_{clasificador}'] = {\n",
    "            'Tiempo inicio':tiempo_inicio,\n",
    "            'Tiempo fin':tiempo_fin,\n",
    "            'Diferencia':diferencia\n",
    "        }\n",
    "        tiempos_clasificadores[f'{nombre_algoritmo}_{clasificador}']['Tiempo fin'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tiempos_clasificadores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar resultados en un único CSV\n",
    "resultados_df = pd.DataFrame(resultados_totales)\n",
    "resultados_df.to_csv('resultados_completos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV de resultados\n",
    "archivo = 'resultados_entrenamiento.csv'\n",
    "df_resultados = pd.read_csv(archivo)\n",
    "\n",
    "# Agrupar por `etiqueta` y `subset`, y seleccionar el modelo con mayor `Accuracy Test` en cada grupo\n",
    "mejores_modelos = df_resultados.loc[df_resultados.groupby(['etiqueta', 'subset'])['Accuracy Test'].idxmax()]\n",
    "\n",
    "# Mostrar los mejores modelos para cada combinación de `etiqueta` y `subset`\n",
    "print(mejores_modelos)\n",
    "\n",
    "# Guardar los resultados en un nuevo archivo CSV si deseas conservarlos\n",
    "mejores_modelos.to_csv(\"mejores_modelos_por_etiqueta_subset.csv\", index=False, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hora_fin_codigo = datetime.datetime.now()\n",
    "print(hora_fin_codigo)\n",
    "print(hora_fin_codigo - hora_inicio_codigo)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPEDb2wd1Jow/Gow/yEIRLp",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
